use futures::stream::StreamExt;
use libp2p::{
    gossipsub, mdns, noise,
    swarm::{NetworkBehaviour, SwarmEvent},
    tcp, yamux,
};
use p2p_distributed_tswap::map::map::MAP;
use p2p_distributed_tswap::map::task_generator::{Task, TaskGeneratorAgent};
use p2p_distributed_tswap::map::task_metrics::{
    PathComputationMetrics, TaskMetric, TaskMetricsCollector,
};

use serde::{Deserialize, Serialize};
use std::cmp::Ordering;
use std::collections::HashMap;
use std::collections::{BinaryHeap, HashSet, hash_map::DefaultHasher};
use std::error::Error;
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use std::time::Duration;
use tokio::{io, io::AsyncBufReadExt, select};

type Point = (usize, usize);

fn parse_map() -> Vec<Vec<char>> {
    let grid = MAP
        .replace('\r', "")
        .lines()
        .filter(|l| !l.trim().is_empty())
        .map(|l| l.chars().collect::<Vec<char>>())
        .collect::<Vec<_>>();

    grid
}

#[derive(Clone)]
struct Node {
    id: usize,
    pos: Point,
    neighbors: Vec<usize>,
}

// ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®ç§»å‹•æŒ‡ç¤º
#[derive(Clone, Debug, Serialize, Deserialize)]
struct MoveInstruction {
    peer_id: String,
    next_pos: Point,
    timestamp: u64,
}

// ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒè¿½è·¡ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹
#[derive(Clone, Debug)]
struct AgentState {
    peer_id: String,
    current_pos: Point,
    goal_pos: Option<Point>,
    path: Vec<Point>,
    task: Option<Task>,
    task_phase: TaskPhase, // pickupå‰ã€deliveryå‰ã€å®Œäº†
}

#[derive(Clone, Debug, PartialEq)]
enum TaskPhase {
    Idle,
    MovingToPickup,
    MovingToDelivery,
}

#[derive(NetworkBehaviour)]
struct MapdBehaviour {
    gossipsub: gossipsub::Behaviour,
    mdns: mdns::tokio::Behaviour,
}

fn get_path(start: usize, goal: usize, nodes: &[Node]) -> Vec<usize> {
    if start == goal {
        return vec![start];
    }

    #[derive(Clone)]
    struct AstarNode {
        node_id: usize,
        g_cost: usize,
        f_cost: usize,
    }

    impl PartialEq for AstarNode {
        fn eq(&self, other: &Self) -> bool {
            self.f_cost == other.f_cost
        }
    }

    impl Eq for AstarNode {}

    impl PartialOrd for AstarNode {
        fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
            Some(self.cmp(other))
        }
    }

    impl Ord for AstarNode {
        fn cmp(&self, other: &Self) -> Ordering {
            other
                .f_cost
                .cmp(&self.f_cost)
                .then_with(|| other.g_cost.cmp(&self.g_cost))
        }
    }

    let mut open_list = BinaryHeap::new();
    let mut came_from = HashMap::new();
    let mut g_score = HashMap::new();

    let heuristic = |node_id: usize| -> usize {
        let (x1, y1) = nodes[node_id].pos;
        let (x2, y2) = nodes[goal].pos;
        ((x1 as isize - x2 as isize).abs() + (y1 as isize - y2 as isize).abs()) as usize
    };

    g_score.insert(start, 0);
    let start_node = AstarNode {
        node_id: start,
        g_cost: 0,
        f_cost: heuristic(start),
    };
    open_list.push(start_node);

    while let Some(current) = open_list.pop() {
        let current_id = current.node_id;

        if current_id == goal {
            let mut path = vec![];
            let mut current_node = current_id;
            path.push(current_node);

            while let Some(&parent) = came_from.get(&current_node) {
                path.push(parent);
                current_node = parent;
            }
            path.reverse();
            return path;
        }

        for &neighbor_id in &nodes[current_id].neighbors {
            let tentative_g = current.g_cost + 1;

            if tentative_g < *g_score.get(&neighbor_id).unwrap_or(&usize::MAX) {
                came_from.insert(neighbor_id, current_id);
                g_score.insert(neighbor_id, tentative_g);

                let h_cost = heuristic(neighbor_id);
                let f_cost = tentative_g + h_cost;

                let neighbor_node = AstarNode {
                    node_id: neighbor_id,
                    g_cost: tentative_g,
                    f_cost,
                };

                open_list.push(neighbor_node);
            }
        }
    }

    vec![start]
}

// ä¸­å¤®é›†æ¨©çš„ãªçµŒè·¯è¨ˆç”»ï¼ˆè¡çªå›é¿ä»˜ãï¼‰
fn plan_all_paths(
    agents: &mut [AgentState],
    pos2id: &HashMap<Point, usize>,
    nodes: &[Node],
) -> Vec<MoveInstruction> {
    let mut instructions = vec![];
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();

    // ã“ã®æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§äºˆç´„ã•ã‚ŒãŸä½ç½®ã‚’è¿½è·¡
    let mut reserved_positions: HashMap<Point, String> = HashMap::new();

    // ã¾ãšã€ã‚´ãƒ¼ãƒ«ã«ã„ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãã®å ´ã«ç•™ã¾ã‚‹
    for agent in agents.iter() {
        if let Some(goal) = agent.goal_pos {
            if agent.current_pos == goal {
                reserved_positions.insert(agent.current_pos, agent.peer_id.clone());
            }
        }
    }

    // æ¬¡ã«ã€ã‚´ãƒ¼ãƒ«ã«ã„ãªã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç§»å‹•ã‚’è¨ˆç”»
    for agent in agents.iter_mut() {
        if let Some(goal) = agent.goal_pos {
            if agent.current_pos == goal {
                // ã‚´ãƒ¼ãƒ«ã§å¾…æ©Ÿ
                instructions.push(MoveInstruction {
                    peer_id: agent.peer_id.clone(),
                    next_pos: agent.current_pos,
                    timestamp,
                });
                continue;
            }

            // ã¾ã çµŒè·¯ãŒè¨ˆç®—ã•ã‚Œã¦ã„ãªã‘ã‚Œã°è¨ˆç®—
            if agent.path.is_empty() {
                if let (Some(&start_id), Some(&goal_id)) =
                    (pos2id.get(&agent.current_pos), pos2id.get(&goal))
                {
                    let path_ids = get_path(start_id, goal_id, nodes);
                    agent.path = path_ids.iter().map(|&id| nodes[id].pos).collect();
                }
            }

            // çµŒè·¯ã‹ã‚‰æ¬¡ã®ä½ç½®ã‚’å–å¾—
            if agent.path.len() > 1 {
                let next_pos = agent.path[1];

                // æ¬¡ã®ä½ç½®ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if !reserved_positions.contains_key(&next_pos) {
                    reserved_positions.insert(next_pos, agent.peer_id.clone());
                    instructions.push(MoveInstruction {
                        peer_id: agent.peer_id.clone(),
                        next_pos,
                        timestamp,
                    });

                    // ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç¾åœ¨ä½ç½®ã¨çµŒè·¯ã‚’æ›´æ–°
                    agent.current_pos = next_pos;
                    agent.path.remove(0);
                } else {
                    // è¡çªå›é¿ã®ãŸã‚å¾…æ©Ÿ
                    instructions.push(MoveInstruction {
                        peer_id: agent.peer_id.clone(),
                        next_pos: agent.current_pos,
                        timestamp,
                    });
                }
            } else {
                // çµŒè·¯ãªã—ã€å¾…æ©Ÿ
                instructions.push(MoveInstruction {
                    peer_id: agent.peer_id.clone(),
                    next_pos: agent.current_pos,
                    timestamp,
                });
            }
        } else {
            // ã‚´ãƒ¼ãƒ«ãªã—ã€å¾…æ©Ÿ
            instructions.push(MoveInstruction {
                peer_id: agent.peer_id.clone(),
                next_pos: agent.current_pos,
                timestamp,
            });
        }
    }

    instructions
}

fn try_assign_pending_tasks<'a>(
    pending: &mut usize,
    agent_states: &mut HashMap<String, AgentState>,
    task_gen: &mut TaskGeneratorAgent<'a>,
    metrics_collector: &mut TaskMetricsCollector,
    task_peer_map: &mut HashMap<u64, String>,
    swarm: &mut libp2p::Swarm<MapdBehaviour>,
    topic: &gossipsub::IdentTopic,
    task_counter: &mut u64,
) -> usize {
    let mut assigned = 0;

    while *pending > 0 {
        let Some(peer_id_str) = agent_states
            .iter()
            .find(|(_, state)| state.task.is_none())
            .map(|(peer_id, _)| peer_id.clone())
        else {
            break;
        };

        let Some(mut task) = task_gen.generate_task() else {
            println!("âš ï¸  Task generation failed (not enough free cells)");
            break;
        };

        *task_counter += 1;
        let task_id = *task_counter;
        task.peer_id = Some(peer_id_str.clone());
        task.task_id = Some(task_id);

        let metric = TaskMetric::new(task_id, peer_id_str.clone());
        metrics_collector.add_metric(metric);

        match serde_json::to_vec(&task) {
            Ok(task_bytes) => match swarm
                .behaviour_mut()
                .gossipsub
                .publish(topic.clone(), task_bytes)
            {
                Ok(_) => {
                    if let Some(agent) = agent_states.get_mut(&peer_id_str) {
                        agent.task = Some(task.clone());
                        agent.goal_pos = Some(task.pickup);
                        agent.path.clear();
                        agent.task_phase = TaskPhase::MovingToPickup;
                    }
                    task_peer_map.insert(task_id, peer_id_str.clone());
                    *pending -= 1;
                    assigned += 1;
                    println!(
                        "âœ… Task {} assigned to {}",
                        task_id,
                        &peer_id_str[..std::cmp::min(8, peer_id_str.len())]
                    );
                }
                Err(e) => {
                    println!("âš ï¸  Publish error: {e:?}");
                    break;
                }
            },
            Err(e) => {
                println!("âš ï¸  Task serialization error: {e:?}");
                break;
            }
        }
    }

    assigned
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸ¢ ============================================");
    println!("ğŸ¢ [CENTRALIZED MANAGER] Starting...");
    println!("ğŸ¢ All pathfinding will be done centrally!");
    println!("ğŸ¢ ============================================");

    let args: Vec<String> = std::env::args().collect();
    let ignore_mdns = args.contains(&"--clean".to_string());

    if ignore_mdns {
        println!("ğŸ§¹ Running in CLEAN mode - ignoring mDNS discoveries");
    }

    let mut swarm = libp2p::SwarmBuilder::with_new_identity()
        .with_tokio()
        .with_tcp(
            tcp::Config::default(),
            noise::Config::new,
            yamux::Config::default,
        )?
        .with_behaviour(|key| {
            let message_id_fn = |message: &gossipsub::Message| {
                let mut s = DefaultHasher::new();
                message.data.hash(&mut s);
                gossipsub::MessageId::from(s.finish().to_string())
            };

            let gossipsub_config = gossipsub::ConfigBuilder::default()
                .heartbeat_interval(Duration::from_millis(500))
                .heartbeat_initial_delay(Duration::from_millis(100))
                .mesh_n_low(1)
                .mesh_n(2)
                .mesh_n_high(3)
                .validation_mode(gossipsub::ValidationMode::Strict)
                .message_id_fn(message_id_fn)
                .build()
                .map_err(io::Error::other)?;

            let gossipsub = gossipsub::Behaviour::new(
                gossipsub::MessageAuthenticity::Signed(key.clone()),
                gossipsub_config,
            )?;

            let mdns =
                mdns::tokio::Behaviour::new(mdns::Config::default(), key.public().to_peer_id())?;
            Ok(MapdBehaviour { gossipsub, mdns })
        })?
        .build();

    let topic = gossipsub::IdentTopic::new("mapd");
    swarm.behaviour_mut().gossipsub.subscribe(&topic)?;
    println!("ğŸ†” Manager Peer ID: {}", swarm.local_peer_id());

    let grid = Arc::new(parse_map());
    let mut task_gen = TaskGeneratorAgent::new(&grid);
    let mut stdin = io::BufReader::new(io::stdin()).lines();

    swarm.listen_on("/ip4/0.0.0.0/tcp/0".parse()?)?;

    // çµŒè·¯æ¢ç´¢ç”¨ã®ãƒãƒ¼ãƒ‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
    let mut pos2id = HashMap::new();
    let mut id2pos = vec![];
    let mut node_id_counter = 0;
    let h = grid.len();
    let w = grid[0].len();
    for y in 0..h {
        for x in 0..w {
            if grid[y][x] != '@' {
                pos2id.insert((x, y), node_id_counter);
                id2pos.push((x, y));
                node_id_counter += 1;
            }
        }
    }
    let mut nodes = vec![];
    for (id, &(x, y)) in id2pos.iter().enumerate() {
        let mut neighbors = vec![];
        for (dx, dy) in [(0, 1), (1, 0), (0, -1), (-1, 0)] {
            let nx = x as isize + dx;
            let ny = y as isize + dy;
            if nx >= 0 && ny >= 0 {
                let npos = (nx as usize, ny as usize);
                if pos2id.contains_key(&npos) {
                    neighbors.push(pos2id[&npos]);
                }
            }
        }
        nodes.push(Node {
            id,
            pos: (x, y),
            neighbors,
        });
    }

    tokio::time::sleep(Duration::from_millis(500)).await;

    println!("ğŸ“‹ Commands:");
    println!("  - 'task': Generate and assign task to an available agent");
    println!("  - 'tasks <N>': Generate and assign N tasks");
    println!("  - 'metrics': Show task and path statistics");
    println!("  - 'save <filename>': Save task metrics to CSV");
    println!("  - 'save path <filename>': Save path computation metrics to CSV");
    println!("  - 'reset': Clear all state");
    println!("â³ Waiting for Gossipsub mesh setup...");

    tokio::time::sleep(Duration::from_secs(1)).await;
    println!("âœ… [CENTRALIZED MANAGER] Ready!");

    let mut known_peers: HashSet<libp2p::PeerId> = HashSet::new();
    let mut subscribed_peers: HashSet<libp2p::PeerId> = HashSet::new();
    let mut task_counter: u64 = 0;
    let mut metrics_collector = TaskMetricsCollector::new();
    let mut path_metrics = PathComputationMetrics::new();

    // ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒè¿½è·¡ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
    let mut agent_states: HashMap<String, AgentState> = HashMap::new();
    let mut task_peer_map: HashMap<u64, String> = HashMap::new();
    let mut pending_task_requests: usize = 0;

    // å®šæœŸçš„ãªçµŒè·¯è¨ˆç”»
    let mut last_planning = std::time::Instant::now();
    let planning_interval = Duration::from_millis(200);

    loop {
        select! {
            Ok(Some(line)) = stdin.next_line() => {
                let trimmed = line.trim();

                if trimmed == "metrics" {
                    let stats = metrics_collector.get_statistics();
                    println!("{}", stats);
                    if let Some(path_stats) = path_metrics.get_statistics() {
                        println!("{}", path_stats);
                    } else {
                        println!("â±ï¸ Path Computation: no samples yet");
                    }
                    continue;
                }

                if trimmed == "reset" {
                    known_peers.clear();
                    subscribed_peers.clear();
                    agent_states.clear();
                    task_peer_map.clear();
                    metrics_collector = TaskMetricsCollector::new();
                    task_counter = 0;
                    path_metrics.clear();
                    println!("âœ… All state cleared!");
                    continue;
                }

                if trimmed.starts_with("save path ") {
                    let filename = trimmed["save path ".len()..].trim();
                    if filename.is_empty() {
                        println!("âš ï¸  Usage: save path <filename>");
                    } else {
                        match std::fs::write(filename, path_metrics.to_csv_string()) {
                            Ok(_) => println!("ğŸ’¾ Saved path metrics to {}", filename),
                            Err(e) => println!("âš ï¸  Failed to save path metrics: {e:?}"),
                        }
                    }
                    continue;
                }

                if trimmed.starts_with("save ") {
                    let filename = &trimmed[5..];
                    let csv_content = metrics_collector.to_csv_string();
                    match std::fs::write(filename, csv_content) {
                        Ok(_) => println!("âœ… Metrics saved to {}", filename),
                        Err(e) => println!("âš ï¸  Failed to save: {e:?}"),
                    }
                    continue;
                }

                if trimmed.starts_with("tasks ") {
                    let num_str = &trimmed[6..];
                    if let Ok(num_tasks) = num_str.parse::<usize>() {
                        pending_task_requests += num_tasks;
                        let sent_count = try_assign_pending_tasks(
                            &mut pending_task_requests,
                            &mut agent_states,
                            &mut task_gen,
                            &mut metrics_collector,
                            &mut task_peer_map,
                            &mut swarm,
                            &topic,
                            &mut task_counter,
                        );
                        println!(
                            "ğŸ¢ [CENTRALIZED] Requested {}, assigned {} immediately (pending: {})",
                            num_tasks, sent_count, pending_task_requests
                        );
                        continue;
                    }
                }

                if trimmed == "task" {
                    pending_task_requests += 1;
                    let sent_count = try_assign_pending_tasks(
                        &mut pending_task_requests,
                        &mut agent_states,
                        &mut task_gen,
                        &mut metrics_collector,
                        &mut task_peer_map,
                        &mut swarm,
                        &topic,
                        &mut task_counter,
                    );
                    if sent_count == 0 {
                        println!("âš ï¸  No available agents right now (pending: {})", pending_task_requests);
                    }
                    continue;
                }

                // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¬é–‹
                if let Err(e) = swarm.behaviour_mut().gossipsub.publish(topic.clone(), trimmed.as_bytes()) {
                    println!("âš ï¸  Publish error: {e:?}");
                }
            }

            // å®šæœŸçš„ãªä¸­å¤®é›†æ¨©çš„çµŒè·¯è¨ˆç”»
            _ = tokio::time::sleep(Duration::from_millis(100)), if last_planning.elapsed() > planning_interval => {
                if !agent_states.is_empty() {
                    let mut agents: Vec<AgentState> = agent_states.values().cloned().collect();
                    let num_agents = agents.len();
                    let plan_start = std::time::Instant::now();
                    let instructions = plan_all_paths(&mut agents, &pos2id, &nodes);
                    let elapsed = plan_start.elapsed();

                    // å…¬å¹³ãªæ¯”è¼ƒã®ãŸã‚ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã®å¹³å‡æ™‚é–“ã‚’è¨˜éŒ²
                    // åˆ†æ•£å‹ã§ã¯å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå€‹åˆ¥ã«è¨ˆç®—ã™ã‚‹ãŸã‚ã€1ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚ãŸã‚Šã®æ™‚é–“ã§æ¯”è¼ƒ
                    let per_agent_duration = elapsed / num_agents as u32;
                    path_metrics.record_duration(per_agent_duration);

                    println!(
                        "â±ï¸ Central path planning for {} agents took {:.3} ms (avg {:.3} ms/agent)",
                        num_agents,
                        elapsed.as_secs_f64() * 1000.0,
                        per_agent_duration.as_secs_f64() * 1000.0
                    );

                    // ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°
                    for agent in agents {
                        // pickup/deliveryã«åˆ°é”ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                        if let Some(task) = &agent.task {
                            if agent.task_phase == TaskPhase::MovingToPickup && agent.current_pos == task.pickup {
                                // pickupã«åˆ°é”ã€æ¬¡ã¯deliveryã¸
                                if let Some(state) = agent_states.get_mut(&agent.peer_id) {
                                    state.goal_pos = Some(task.delivery);
                                    state.path.clear();
                                    state.task_phase = TaskPhase::MovingToDelivery;
                                    println!("ğŸ“¦ Agent {} reached PICKUP, now moving to DELIVERY", &agent.peer_id[..std::cmp::min(8, agent.peer_id.len())]);
                                }
                            }
                        }
                        agent_states.insert(agent.peer_id.clone(), agent);
                    }

                    // ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç§»å‹•æŒ‡ç¤ºã‚’é€ä¿¡
                    for instruction in instructions {
                        let msg = serde_json::json!({
                            "type": "move_instruction",
                            "peer_id": instruction.peer_id,
                            "next_pos": [instruction.next_pos.0, instruction.next_pos.1],
                            "timestamp": instruction.timestamp
                        }).to_string();

                        let _ = swarm.behaviour_mut().gossipsub.publish(topic.clone(), msg.as_bytes());
                    }
                }
                last_planning = std::time::Instant::now();
            }

            event = swarm.select_next_some() => match event {
                SwarmEvent::NewListenAddr { address, .. } => {
                    println!("ğŸ§ Listening on {address}");
                }
                SwarmEvent::Behaviour(MapdBehaviourEvent::Mdns(mdns::Event::Discovered(list))) if !ignore_mdns => {
                    for (peer_id, _multiaddr) in list {
                        if !known_peers.contains(&peer_id) {
                            println!("ğŸ” mDNS discovered: {}", peer_id);
                            swarm.behaviour_mut().gossipsub.add_explicit_peer(&peer_id);
                            known_peers.insert(peer_id);
                        }
                    }
                }
                SwarmEvent::Behaviour(MapdBehaviourEvent::Mdns(mdns::Event::Expired(list))) => {
                    for (peer_id, _multiaddr) in list {
                        println!("â° mDNS expired: {}", peer_id);
                        if !ignore_mdns {
                            swarm.behaviour_mut().gossipsub.remove_explicit_peer(&peer_id);
                        }
                    }
                }
                SwarmEvent::Behaviour(MapdBehaviourEvent::Gossipsub(gossipsub::Event::Subscribed { peer_id, topic })) => {
                    println!("ğŸ”— Peer {} subscribed to topic: {}", peer_id, topic);
                    subscribed_peers.insert(peer_id.clone());

                    // Subscribedã‚¤ãƒ™ãƒ³ãƒˆå¾Œã€ãã®ãƒ”ã‚¢ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã§ãã‚‹ã‚ˆã†ã«å°‘ã—å¾…ã¤
                    let peer_short = peer_id.to_base58();
                    println!("ğŸ‘‚ Now listening for messages from {}", &peer_short[..std::cmp::min(8, peer_short.len())]);
                }
                SwarmEvent::Behaviour(MapdBehaviourEvent::Gossipsub(gossipsub::Event::Message { message, .. })) => {
                    let source_str = message.source.as_ref().map(|s| {
                        let full = s.to_base58();
                        full[..std::cmp::min(8, full.len())].to_string()
                    });
                    println!("ğŸ“¨ [DEBUG] Received message from: {:?}, size: {} bytes", source_str, message.data.len());

                    if let Ok(val) = serde_json::from_slice::<serde_json::Value>(&message.data) {
                        // ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®ä½ç½®æ›´æ–°
                        if val.get("type") == Some(&serde_json::Value::String("position_update".to_string())) {
                            println!("ğŸ“ [DEBUG] Received position_update message: {:?}", val);
                            if let (Some(peer_id), Some(pos_arr)) = (val.get("peer_id"), val.get("position")) {
                                if let (Some(peer_id_str), Some(pos)) = (peer_id.as_str(), pos_arr.as_array()) {
                                    if pos.len() == 2 {
                                        if let (Some(x), Some(y)) = (pos[0].as_u64(), pos[1].as_u64()) {
                                            let position = (x as usize, y as usize);
                                            println!("âœ… [MANAGER] Agent {} position: {:?}", peer_id_str, position);

                                            let is_new = !agent_states.contains_key(peer_id_str);
                                            agent_states.entry(peer_id_str.to_string())
                                                .and_modify(|state| {
                                                    state.current_pos = position;
                                                })
                                                .or_insert(AgentState {
                                                    peer_id: peer_id_str.to_string(),
                                                    current_pos: position,
                                                    goal_pos: None,
                                                    path: vec![],
                                                    task: None,
                                                    task_phase: TaskPhase::Idle,
                                                });

                                            if is_new {
                                                println!("ğŸ†• [MANAGER] New agent registered: {} at {:?}", peer_id_str, position);
                                                println!("ğŸ‘¥ [MANAGER] Total available agents: {}", agent_states.len());
                                            }

                                            let newly_assigned = try_assign_pending_tasks(
                                                &mut pending_task_requests,
                                                &mut agent_states,
                                                &mut task_gen,
                                                &mut metrics_collector,
                                                &mut task_peer_map,
                                                &mut swarm,
                                                &topic,
                                                &mut task_counter,
                                            );

                                            if newly_assigned > 0 {
                                                println!(
                                                    "ğŸš€ Assigned {} pending tasks after position update",
                                                    newly_assigned
                                                );
                                            }
                                        }
                                    }
                                }
                            }
                        }

                        // ã‚¿ã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹
                        if let Some(metric_type) = val.get("type").and_then(|v| v.as_str()) {
                            if let Some(task_id) = val.get("task_id").and_then(|v| v.as_u64()) {
                                match metric_type {
                                    "task_metric_received" => metrics_collector.update_received(task_id),
                                    "task_metric_started" => metrics_collector.update_started(task_id),
                                    "task_metric_completed" => metrics_collector.update_completed(task_id),
                                    _ => {}
                                }
                            }
                        }

                        // ã‚¿ã‚¹ã‚¯å®Œäº†
                        if val.get("status") == Some(&serde_json::Value::String("done".to_string())) {
                            if let Some(task_id) = val.get("task_id").and_then(|v| v.as_u64()) {
                                println!("âœ… Task {} completed!", task_id);

                                if let Some(peer_id_str) = task_peer_map.get(&task_id) {
                                    if let Some(agent) = agent_states.get_mut(peer_id_str) {
                                        agent.task = None;
                                        agent.goal_pos = None;
                                        agent.path.clear();
                                        agent.task_phase = TaskPhase::Idle;
                                    }
                                }

                                let newly_assigned = try_assign_pending_tasks(
                                    &mut pending_task_requests,
                                    &mut agent_states,
                                    &mut task_gen,
                                    &mut metrics_collector,
                                    &mut task_peer_map,
                                    &mut swarm,
                                    &topic,
                                    &mut task_counter,
                                );

                                if newly_assigned > 0 {
                                    println!(
                                        "ğŸš€ Assigned {} pending tasks after completion",
                                        newly_assigned
                                    );
                                }
                            }
                        }
                    }
                }
                _ => {}
            }
        }
    }
}
